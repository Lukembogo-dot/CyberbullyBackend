ğŸ Backend README (/backend/README.md)

ğŸ›¡ï¸ AI Content Guard - Backend (Kafka + ML)

This is the engine of the project. It handles real-time data streaming from YouTube, runs AI inference via a custom Scikit-Learn model, and persists high-risk data to a Neon PostgreSQL database.

ğŸ“‚ Folder Structure

backend/
â”œâ”€â”€ db/                # Database configuration & Models
â”‚   â”œâ”€â”€ database.py    # SQLAlchemy engine
â”‚   â””â”€â”€ models.py      # PostgreSQL schema
â”œâ”€â”€ kafka/             # Streaming logic
â”‚   â””â”€â”€ consumer.py    # Main Kafka consumer & ML loop
â”œâ”€â”€ ml/                # Machine Learning assets
â”‚   â””â”€â”€ model.pkl      # Trained Logistic Regression model
â”œâ”€â”€ .env               # Database credentials & API keys
â””â”€â”€ main.py            # FastAPI entry point

ğŸ› ï¸ Installation & Setup

1. Initialize Environment:
```
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt
```
2. Start Kafka: Ensure your Kafka broker is running (via Docker or local install) at localhost:9092.

3. Run the Consumer:
```
$env:PYTHONPATH = "." # Set python path
python kafka/consumer.py
```

4. Start the API:
```
Bash
uvicorn main:app --reload
```
